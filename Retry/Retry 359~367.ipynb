{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf41dfd-1e48-4ea5-9874-9e1a5a3b5cbd",
   "metadata": {},
   "source": [
    "### ライブラリ、データのダウンロード、データの抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e03fed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 前処理にはsklearnライブラリを使っていきます\n",
    "\n",
    "from sklearn import preprocessing\n",
    "# データを読み込みます\n",
    "raw_csv_data =np.loadtxt('Audiobooks-data.csv',delimiter=',')\n",
    "\n",
    "# 最初のIDの列と、ターゲットである最後の列を取り除いた上で変数に代入します\n",
    "unscaled_inputs_all =raw_csv_data[:,1:-1]\n",
    "\n",
    "# 最後の列のデータをターゲットとして変数に代入していきます\n",
    "targets_all = raw_csv_data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c39d53-130f-4bc0-b371-e9747475d728",
   "metadata": {},
   "source": [
    "### targets_all のデータの型の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1de86806-8b91-4c7c-805f-94261ea673f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14084,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85616c8d-4d5c-458d-a671-3f95afa6d223",
   "metadata": {},
   "source": [
    "### 1と0の数を数えて、0と1の数が均等になるように、余分の0をリストに格納する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f49db94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ターゲットの数を数えます\n",
    "num_one_targets =np.sum(targets_all) \n",
    "\n",
    "# 数を数えるための変数を定義します\n",
    "zero_targets_counter = 0\n",
    "# バランスを取る上で不要なデータを入れるためのリストを定義します\n",
    "indices_to_remove = []\n",
    "\n",
    "# ターゲットの数を数え、その数を超える0のデータがあった場合はリストにその値をいれていきます\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i]==0:\n",
    "        zero_targets_counter+=1\n",
    "        if zero_targets_counter>=num_one_targets:\n",
    "           indices_to_remove.append(i)\n",
    "\n",
    "# 入力とターゲットを入れるための変数を定義します\n",
    "# また、バランスが取れていないデータを削除していきます\n",
    "#　0と1の数を揃えた上で全体のデータの数を揃える\n",
    "unscaled_inputs_equal_priors =np.delete(unscaled_inputs_all,indices_to_remove,axis=0)\n",
    "targets_equal_priors = np.delete(targets_all,indices_to_remove,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b03308f-57ec-4bd6-a39f-7fbc53d55283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2237.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_one_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f661c64e-388e-4c63-bbaa-cff11084770a",
   "metadata": {},
   "source": [
    "### インプットデータを標準化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dbd1190-1157-4c81-9b9b-0f99e0626953",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs=preprocessing.scale(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dee27f-3ec8-4078-a60b-6768064321eb",
   "metadata": {},
   "source": [
    "### データをシャッフルして、変数に格納する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e67f24d-b2f3-49d5-80fd-6d1f2da4d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをバッチに分けていくことから、何らかの規則性が生まれないようにデータをシャッフルしていきます\n",
    "shuffled_indices =np.arange(scaled_inputs.shape[0])#行のみを取り出している\n",
    "np.random.shuffle(shuffled_indices)\n",
    "# シャッフルしたデータを変数に入れていきます(行をバラバラにしている)\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets =targets_equal_priors[shuffled_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f2c472-5d9d-4d7d-b2d5-c46dacd17f91",
   "metadata": {},
   "source": [
    "### データの数を数え、訓練用、検証用、テスト用に分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f69a8d6-24a2-4f39-a77e-a8dd0ed1d51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792.0 3578 0.5008384572386808\n",
      "-69.06495890160508 447 -0.1545077380349107\n",
      "12.270527420203045 -2683 -0.004573435490198675\n"
     ]
    }
   ],
   "source": [
    "# データの数を数えます\n",
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "# 80-10-10に分けることを前提として、訓練用と検証用のデータの数を定義していきます(データ型も念の為変換した上で行う)\n",
    "# Naturally, the numbers are integers.\n",
    "train_samples_count = int(0.8*samples_count)\n",
    "validation_samples_count = int(0.1*samples_count)\n",
    "# テスト用のデータの数を定義します\n",
    "test_samples_count = int(samples_count-train_samples_count-train_samples_count)\n",
    "\n",
    "\n",
    "# 訓練用データを作成します\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets =shuffled_targets[:train_samples_count]\n",
    "# 検証用データを作成します\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets =shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "\n",
    "# テスト用データを作成します\n",
    "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
    "test_targets = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
    "\n",
    "\n",
    "\n",
    "# 作成したデータの中の１と０の割合を確認します\n",
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\n",
    "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\n",
    "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea7fa0-6bcf-4c7a-b360-500269b38830",
   "metadata": {},
   "source": [
    "### Ssavezメソッドを使ってデータを保存していきます\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8290f0b2-f9ea-4db6-8f90-2e1925057da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ssavezメソッドを使ってデータを保存していきます\n",
    "np.savez('Audiobooks_data_train',inputs=train_inputs,targets=train_targets)\n",
    "np.savez('Audiobooks_data_validation',inputs=validation_inputs,targets=validation_targets)\n",
    "np.savez('Audiobooks_data_test',inputs=test_inputs,targets=test_targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41770106-6267-450b-aa61-55e9b60a734d",
   "metadata": {},
   "source": [
    "### 機械学習用に新たにライブラリーをインポートする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4c2edb1-af2c-45e6-b447-e5e6349e47d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fujir\\AppData\\Local\\Temp\\ipykernel_10300\\1408153987.py:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_inputs =npz['inputs'].astype(np.float)#データ型も念の為変換した上で行う\n",
      "C:\\Users\\fujir\\AppData\\Local\\Temp\\ipykernel_10300\\1408153987.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_targets =npz['targets'].astype(np.int) #データ型も念の為変換した上で行う\n"
     ]
    }
   ],
   "source": [
    "# 新たに一からコードを書いていきますので、再度ライブラリをインポートします\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# まずは訓練データを一時的に読み込みます\n",
    "npz = np.load('Audiobooks_data_train.npz')\n",
    "\n",
    "# 訓練用のデータを入力とターゲットに分けて変数に代入していきます\n",
    "train_inputs =npz['inputs'].astype(np.float)#データ型も念の為変換した上で行う\n",
    "train_targets =npz['targets'].astype(np.int) #データ型も念の為変換した上で行う\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5879ff-21f7-43d0-af5b-3de3426a4278",
   "metadata": {},
   "source": [
    "### 訓練データを読み込み、訓練用、検証用、テスト用でそれぞれ変数に代入する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "471d3011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fujir\\AppData\\Local\\Temp\\ipykernel_10300\\863552815.py:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  validation_inputs, validation_targets =npz['inputs'].astype(np.float),npz['targets'].astype(np.int) #データ型も念の為変換した上で行う\n",
      "C:\\Users\\fujir\\AppData\\Local\\Temp\\ipykernel_10300\\863552815.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  validation_inputs, validation_targets =npz['inputs'].astype(np.float),npz['targets'].astype(np.int) #データ型も念の為変換した上で行う\n",
      "C:\\Users\\fujir\\AppData\\Local\\Temp\\ipykernel_10300\\863552815.py:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_inputs, test_targets =npz['inputs'].astype(np.float),npz['targets'].astype(np.int) #データ型も念の為変換した上で行う\n",
      "C:\\Users\\fujir\\AppData\\Local\\Temp\\ipykernel_10300\\863552815.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_inputs, test_targets =npz['inputs'].astype(np.float),npz['targets'].astype(np.int) #データ型も念の為変換した上で行う\n"
     ]
    }
   ],
   "source": [
    "# 検証用データを一時的に読み込みます\n",
    "npz = np.load('Audiobooks_data_validation.npz')\n",
    "# 訓練用のデータを入力とターゲットに分けて変数に代入していきます\n",
    "validation_inputs, validation_targets =npz['inputs'].astype(np.float),npz['targets'].astype(np.int) #データ型も念の為変換した上で行う\n",
    "\n",
    "# テストデータを一時的に読み込みます\n",
    "npz = np.load('Audiobooks_data_test.npz')\n",
    "# テスト用のデータを入力とターゲットに分けて変数に代入していきます\n",
    "test_inputs, test_targets =npz['inputs'].astype(np.float),npz['targets'].astype(np.int) #データ型も念の為変換した上で行う"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22efd35c-35bc-4b77-a5ea-194bf0303047",
   "metadata": {},
   "source": [
    "### TensofFlow で入力層、出力層等を定義しモデルを作成。フィットさせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f39c10cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1215 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1208 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1179 test_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:409 update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py:90 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:176 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:612 update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:3301 sparse_categorical_accuracy\n        y_true = array_ops.squeeze(y_true, [-1])\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:4259 squeeze\n        return gen_array_ops.squeeze(input, axis, name)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10042 squeeze\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:591 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3477 _create_op_internal\n        ret = Operation(\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1974 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](Cast_1)' with input shapes: [?,10].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# モデルにデータを入れていきます\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 訓練データの入力\u001b[39;49;00m\n\u001b[0;32m     31\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 訓練データのターゲット\u001b[39;49;00m\n\u001b[0;32m     32\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# バッチサイズ\u001b[39;49;00m\n\u001b[0;32m     33\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 繰り返し回数\u001b[39;49;00m\n\u001b[0;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# アーリーストッピング\u001b[39;49;00m\n\u001b[0;32m     35\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_targets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 検証データの指定\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 結果の見た目を変更\u001b[39;49;00m\n\u001b[0;32m     37\u001b[0m \u001b[43m          \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1123\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1110\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mDataHandler(\n\u001b[0;32m   1111\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1112\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1121\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1122\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[1;32m-> 1123\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m   1135\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1379\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraceContext\u001b[39m\u001b[38;5;124m'\u001b[39m, graph_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep):\n\u001b[0;32m   1378\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1379\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1381\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:780\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 780\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tracing_count()\n\u001b[0;32m    783\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:823\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    821\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 823\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    825\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    826\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    827\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 696\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    700\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2855\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2854\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2855\u001b[0m   graph_function, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3213\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3210\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(args, kwargs)\n\u001b[0;32m   3212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3213\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, args, kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3065\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3060\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3061\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3062\u001b[0m ]\n\u001b[0;32m   3063\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3064\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3066\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3068\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3070\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3073\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3074\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3076\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3077\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3078\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3079\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3080\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3081\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3082\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3083\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:986\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    984\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m--> 986\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m    990\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m    991\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:600\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# We register a variable creator with reduced priority. If an outer\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;66;03m# variable creator is just modifying keyword arguments to the variable\u001b[39;00m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;66;03m# constructor, this will work harmoniously. Since the `scope` registered\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;66;03m# better than the alternative, tracing the initialization graph but giving\u001b[39;00m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;66;03m# the user a variable type they didn't want.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    598\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    599\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m--> 600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:973\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    972\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 973\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    974\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1215 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1208 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1179 test_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:409 update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py:90 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:176 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:612 update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:3301 sparse_categorical_accuracy\n        y_true = array_ops.squeeze(y_true, [-1])\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:4259 squeeze\n        return gen_array_ops.squeeze(input, axis, name)\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10042 squeeze\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:591 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3477 _create_op_internal\n        ret = Operation(\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1974 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\Users\\fujir\\anaconda3\\envs\\py-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](Cast_1)' with input shapes: [?,10].\n"
     ]
    }
   ],
   "source": [
    "# 入力の数と出力の数を定義します\n",
    "input_size = 10\n",
    "output_size = 2\n",
    "# 隠れ層のユニットの数を定義します\n",
    "hidden_layer_size = 30\n",
    "    \n",
    "# モデルを作成していきます\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1番目の隠れ層\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2番目の隠れ層\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 3番目の隠れ層\n",
    "   \n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') # 出力層\n",
    "])\n",
    "\n",
    "\n",
    "# 損失関数と最適化アルゴリズムを定義していきます\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "### 訓練\n",
    "\n",
    "# バッチサイズの設定\n",
    "batch_size = 100\n",
    "\n",
    "# 繰り返し回数の設定\n",
    "max_epochs = 100\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "# モデルにデータを入れていきます\n",
    "model.fit(train_inputs, # 訓練データの入力\n",
    "          train_targets, # 訓練データのターゲット\n",
    "          batch_size=batch_size, # バッチサイズ\n",
    "          epochs=max_epochs, # 繰り返し回数\n",
    "            callbacks=[early_stopping], # アーリーストッピング\n",
    "          validation_data=(validation_inputs, validation_targets), # 検証データの指定\n",
    "          verbose = 2 # 結果の見た目を変更\n",
    "          )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044d0c3e-0019-4f48-b246-e5f3aea128ae",
   "metadata": {},
   "source": [
    "### テストデータでテストを行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7886e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcf16dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc862f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
